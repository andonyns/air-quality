{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/andonyns/air-quality/blob/main/main.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>\n",
    "\n",
    "# Laboratorio 01\n",
    "\n",
    "## Grupo 04\n",
    "- Jorge Ignacio Chavarría Herrera - B82073\n",
    "- Antonio Badilla-Olivas - B80874\n",
    "- Enrique Guillermo Vílchez Lizano - C18477\n",
    "- Andony Nuñez Solano - B04539\n",
    "\n",
    "## Objetivos\n",
    "\n",
    "1. Selección y recolección de parámetros y ciudades.\n",
    "2. Limpiar y transformar los datos para comparaciones.\n",
    "3. Análisis univariable y multivariable. Analizar las tendencias de los indicadores y hacer comparaciones. Incluir posibles correlaciones entre variables.\n",
    "4. Conclusiones y recomendaciones según las políticas ambientales de cada país."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Relevant concepts\n",
    "These are the variables that [OpenAQ](https://openaq.org/) offers to measure air pollution. The definitions were taken from [Clean Air Act](https://www.epa.gov/criteria-air-pollutants/information-pollutant):\n",
    "\n",
    "1. PM (Particular Matter): These particles come in many sizes and shapes and can be made up of hundreds of different chemicals. Some are emitted directly from a source, such as construction sites, unpaved roads, fields, smokestacks or fires. Most particles form in the atmosphere as a result of complex reactions of chemicals such as sulfur dioxide and nitrogen oxides, which are pollutants emitted from power plants, industries and automobiles.\n",
    "\n",
    "  - PM₂.₅ (Particulate Matter 2.5 micrometers or smaller):\n",
    "fine inhalable particles, with diameters that are generally 2.5 micrometers and smaller\n",
    "\n",
    "  - PM₁₀ (Particulate Matter 10 micrometers or smaller):\n",
    "inhalable particles, with diameters that are generally 10 micrometers and smaller\n",
    "\n",
    "2.\tO₃ (Ozone):\n",
    "tropospheric, or ground level ozone, is not emitted directly into the air, but is created by chemical reactions between oxides of nitrogen (NOx) and volatile organic compounds (VOC). This happens when pollutants emitted by cars, power plants, industrial boilers, refineries, chemical plants, and other sources chemically react in the presence of sunlight.\n",
    "\n",
    "3.\tNO₂ (Nitrogen Dioxide):\n",
    "Nitrogen Dioxide (NO2) is one of a group of highly reactive gases known as oxides of nitrogen or nitrogen oxides (NOx). Other nitrogen oxides include nitrous acid and nitric acid. NO2 is used as the indicator for the larger group of nitrogen oxides. NO2 primarily gets in the air from the burning of fuel. NO2 forms from emissions from cars, trucks and buses, power plants, and off-road equipment.\n",
    "\n",
    "4.\tSO₂ (Sulfur Dioxide):\n",
    "SO2 is the component of greatest concern and is used as the indicator for the larger group of gaseous sulfur oxides (SOx).  Other gaseous SOx (such as SO3) are found in the atmosphere at concentrations much lower than SO2. The largest source of SO2 in the atmosphere is the burning of fossil fuels by power plants and other industrial facilities. Smaller sources of SO2 emissions include: industrial processes such as extracting metal from ore; natural sources such as volcanoes; and locomotives, ships and other vehicles and heavy equipment that burn fuel with a high sulfur content.\n",
    "\n",
    "5.\tCO (Carbon Monoxide):\n",
    "CO is a colorless, odorless gas that can be harmful when inhaled in large amounts. CO is released when something is burned. The greatest sources of CO to outdoor air are cars, trucks and other vehicles or machinery that burn fossil fuels. A variety of items in your home such as unvented kerosene and gas space heaters, leaking chimneys and furnaces, and gas stoves also release CO and can affect air quality indoors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: dotenv in /home/codespace/.python/current/lib/python3.12/site-packages (0.9.9)\n",
      "Requirement already satisfied: python-dotenv in /home/codespace/.python/current/lib/python3.12/site-packages (from dotenv) (1.1.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Collecting openaq\n",
      "  Downloading openaq-0.4.0-py3-none-any.whl.metadata (3.3 kB)\n",
      "Requirement already satisfied: httpx==0.28.1 in /home/codespace/.local/lib/python3.12/site-packages (from openaq) (0.28.1)\n",
      "Requirement already satisfied: anyio in /home/codespace/.local/lib/python3.12/site-packages (from httpx==0.28.1->openaq) (4.9.0)\n",
      "Requirement already satisfied: certifi in /home/codespace/.local/lib/python3.12/site-packages (from httpx==0.28.1->openaq) (2025.1.31)\n",
      "Requirement already satisfied: httpcore==1.* in /home/codespace/.local/lib/python3.12/site-packages (from httpx==0.28.1->openaq) (1.0.7)\n",
      "Requirement already satisfied: idna in /home/codespace/.local/lib/python3.12/site-packages (from httpx==0.28.1->openaq) (3.10)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /home/codespace/.local/lib/python3.12/site-packages (from httpcore==1.*->httpx==0.28.1->openaq) (0.14.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in /home/codespace/.local/lib/python3.12/site-packages (from anyio->httpx==0.28.1->openaq) (1.3.1)\n",
      "Requirement already satisfied: typing_extensions>=4.5 in /home/codespace/.local/lib/python3.12/site-packages (from anyio->httpx==0.28.1->openaq) (4.12.2)\n",
      "Downloading openaq-0.4.0-py3-none-any.whl (51 kB)\n",
      "Installing collected packages: openaq\n",
      "Successfully installed openaq-0.4.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install dotenv\n",
    "%pip install openaq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For API requests\n",
    "import requests\n",
    "from urllib.parse import urljoin\n",
    "from openaq import OpenAQ\n",
    "\n",
    "# For env\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# For data manipulation\n",
    "from pprint import pprint\n",
    "import pandas as pd\n",
    "import pickle as pkl\n",
    "\n",
    "import time\n",
    "import logging\n",
    "import sys\n",
    "\n",
    "from dataclasses import dataclass\n",
    "import re\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_color(text: str, color: str = \"green\") -> str:\n",
    "    \"\"\"\n",
    "    Set the color of the text.\n",
    "    :param text: The text to color.\n",
    "    :param color: The color to set.\n",
    "    :return: The colored text.\n",
    "    \"\"\"\n",
    "    colors = {\n",
    "        \"green\": \"\\033[32m\",\n",
    "        \"yellow\": \"\\033[33m\",\n",
    "        \"red\": \"\\033[31m\",\n",
    "        \"blue\": \"\\033[34m\",\n",
    "        \"orange\": \"\\033[38;5;214m\",\n",
    "        \"reset\": \"\\033[0m\",\n",
    "    }\n",
    "    return f\"{colors[color]}{text}{colors['reset']}\"\n",
    "\n",
    "class StdOutLogger(logging.Logger):\n",
    "    def __init__(self):\n",
    "        super().__init__(__name__)\n",
    "        self.logger = logging.getLogger(__name__)\n",
    "        # To log events\n",
    "        logging.basicConfig(\n",
    "            level=logging.INFO,\n",
    "            format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',\n",
    "            datefmt='%Y-%m-%d %H:%M:%S',\n",
    "            stream=sys.stdout\n",
    "        )\n",
    "\n",
    "    def info(self, message: str):\n",
    "        self.logger.info(set_color(message, \"blue\"))\n",
    "        \n",
    "    def success(self, message: str):\n",
    "        self.logger.info(set_color(message, \"green\"))\n",
    "\n",
    "    def warning(self, message: str):\n",
    "        self.logger.warning(set_color(message, \"orange\"))\n",
    "\n",
    "    def critical(self, message: str):\n",
    "        self.logger.critical(set_color(message, \"red\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load logger\n",
    "logger = StdOutLogger()\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = \"data\"\n",
    "if not os.path.isdir(DATA_DIR):\n",
    "    os.mkdir(DATA_DIR)\n",
    "\n",
    "BASE_API_URL = \"https://api.openaq.org/v3/\"\n",
    "\n",
    "HEADERS = {\"X-API-Key\": os.getenv(\"API_KEY\")}\n",
    "\n",
    "LOCATIONS_ENDPOINT = urljoin(BASE_API_URL, \"locations/{location_id}\")\n",
    "MEASUREMENTS_ENDPOINT = urljoin(BASE_API_URL, \"sensors/{sensor_id}/measurements/daily\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_data(\n",
    "    base_url: str,\n",
    "    headers: dict[str, str] | None = None,\n",
    "    parameters: dict[str, any] | None = None,\n",
    "    query_parameters: dict[str, any] | None = None,\n",
    "    verbose: bool = False\n",
    "):\n",
    "    \"\"\"\n",
    "    Fetch data from the OpenAQ API.\n",
    "    :param base_url: The base URL for the API endpoint.\n",
    "    :param headers: Optional headers to include in the request.\n",
    "    :param parameters: Optional parameters to format the URL.\n",
    "    :param query_parameters: Optional query parameters to include in the request.\n",
    "    :param verbose: If True, print the response headers.\n",
    "    :return: The JSON response from the API.\n",
    "    \"\"\"\n",
    "\n",
    "    \n",
    "    if parameters is not None:\n",
    "        base_url = base_url.format(**parameters)\n",
    "\n",
    "    if query_parameters is not None:\n",
    "        base_url = urljoin(base_url, \"?\" + \"&\".join(f\"{k}={v}\" for k, v in query_parameters.items()))\n",
    "\n",
    "    if headers is not None:\n",
    "        response = requests.get(\n",
    "            url=base_url,\n",
    "            headers=headers,\n",
    "        )\n",
    "    else:\n",
    "        response = requests.get(\n",
    "            url=base_url,\n",
    "        )\n",
    "\n",
    "    if response.status_code != 200:\n",
    "        raise Exception(\n",
    "            f\"Request failed with status: {response.status_code}. Reason: {response.text}\"\n",
    "        )\n",
    "    if verbose:\n",
    "        pprint(response.headers)\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'meta': {'found': 1,\n",
      "          'limit': 100,\n",
      "          'name': 'openaq-api',\n",
      "          'page': 1,\n",
      "          'website': '/'},\n",
      " 'results': [{'bounds': [-84.0417, 9.938, -84.0417, 9.938],\n",
      "              'coordinates': {'latitude': 9.938, 'longitude': -84.0417},\n",
      "              'country': {'code': 'CR', 'id': 29, 'name': 'Costa Rica'},\n",
      "              'datetimeFirst': {'local': '2024-09-19T14:01:34-06:00',\n",
      "                                'utc': '2024-09-19T20:01:34Z'},\n",
      "              'datetimeLast': {'local': '2025-04-20T15:54:21-06:00',\n",
      "                               'utc': '2025-04-20T21:54:21Z'},\n",
      "              'distance': None,\n",
      "              'id': 3070644,\n",
      "              'instruments': [{'id': 4, 'name': 'Clarity Sensor'}],\n",
      "              'isMobile': False,\n",
      "              'isMonitor': False,\n",
      "              'licenses': [{'attribution': {'name': 'Clarity', 'url': None},\n",
      "                            'dateFrom': '2021-10-20',\n",
      "                            'dateTo': None,\n",
      "                            'id': 38,\n",
      "                            'name': 'CC0 1.0'}],\n",
      "              'locality': None,\n",
      "              'name': 'NASA GSFC Rutgers Calib. N13',\n",
      "              'owner': {'id': 9, 'name': 'Clarity'},\n",
      "              'provider': {'id': 166, 'name': 'Clarity'},\n",
      "              'sensors': [{'id': 10669679,\n",
      "                           'name': 'pm25 µg/m³',\n",
      "                           'parameter': {'displayName': 'PM2.5',\n",
      "                                         'id': 2,\n",
      "                                         'name': 'pm25',\n",
      "                                         'units': 'µg/m³'}}],\n",
      "              'timezone': 'America/Costa_Rica'}]}\n"
     ]
    }
   ],
   "source": [
    "# Costa Rica example\n",
    "cr_location_id = 3070644\n",
    "\n",
    "cr_location_data = fetch_data(\n",
    "    base_url=LOCATIONS_ENDPOINT,\n",
    "    headers=HEADERS,\n",
    "    parameters={\"location_id\": cr_location_id},\n",
    ").json()\n",
    "pprint(cr_location_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "last page: 13\n",
      "Total pages: 13\n"
     ]
    }
   ],
   "source": [
    "# Get the first sensor\n",
    "sensor = cr_location_data[\"results\"][0][\"sensors\"][0]\n",
    "not_finished = True\n",
    "query_params = {\"limit\": 1000, \"page\": 1}\n",
    "\n",
    "while not_finished: \n",
    "    sensor_id = sensor[\"id\"]\n",
    "    sensor_data = fetch_data(\n",
    "        base_url=MEASUREMENTS_ENDPOINT,\n",
    "        headers=HEADERS,\n",
    "        parameters={\"sensor_id\": sensor_id},\n",
    "        query_parameters=query_params,\n",
    "    ).json()\n",
    "    if len(sensor_data[\"results\"]) < 1000:\n",
    "        print(f\"last page: {sensor_data[\"meta\"][\"page\"]}\")\n",
    "        not_finished = False\n",
    "\n",
    "    else:\n",
    "        query_params[\"page\"] += 1\n",
    "\n",
    "print(f\"Total pages: {query_params[\"page\"]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_location_sensors_data(\n",
    "    location_id: int,\n",
    "):\n",
    "    logger.info(f\"Fetching data for location ID: {location_id}...\")\n",
    "    location_data = fetch_data(\n",
    "        base_url=LOCATIONS_ENDPOINT,\n",
    "        headers=HEADERS,\n",
    "        parameters={\"location_id\": location_id},\n",
    "    ).json()\n",
    "\n",
    "    logger.success(f\"Finished fetch for data of location ID: {location_id}\")\n",
    "\n",
    "    # Get all sensors info\n",
    "    sensors_data = {}\n",
    "    \n",
    "\n",
    "    # Iterate through all sensors\n",
    "    for i, sensor in enumerate(location_data[\"results\"][0][\"sensors\"]):\n",
    "        query_params = {\"limit\": 100, \"page\": 1}\n",
    "        logger.info(f\"Processing sensor number {i}\")\n",
    "        sensor_id = sensor[\"id\"]\n",
    "        sensors_data[sensor_id] = []\n",
    "\n",
    "        not_finished = True\n",
    "        while not_finished:\n",
    "\n",
    "\n",
    "            sensor_response = fetch_data(\n",
    "                base_url=MEASUREMENTS_ENDPOINT,\n",
    "                headers=HEADERS,\n",
    "                parameters={\"sensor_id\": sensor_id},\n",
    "                query_parameters=query_params,\n",
    "            )\n",
    "\n",
    "            sensor_data = sensor_response.json()\n",
    "\n",
    "            logger.info(f\"Processing sensor number {i}, page {sensor_data[\"meta\"][\"page\"]}\")\n",
    "            logger.warning(f\"Remaining requests: {sensor_response.headers[\"X-Ratelimit-Remaining\"]}\")\n",
    "            \n",
    "            sensors_data[sensor_id].append(sensor_data)  \n",
    "\n",
    "            if len(sensor_data[\"results\"]) < 100:\n",
    "                not_finished = False\n",
    "            else:\n",
    "                query_params[\"page\"] += 1\n",
    "            \n",
    "            if (sensor_response.headers[\"X-Ratelimit-Remaining\"] == \"1\"):\n",
    "                logger.warning(f\"Reached rate limit. Waiting for {sensor_response.headers[\"X-Ratelimit-Reset\"]} seconds.\")\n",
    "                time.sleep(int(sensor_response.headers[\"X-Ratelimit-Reset\"]))\n",
    "\n",
    "        logger.success(f\"Finished processing sensor number {i}\")\n",
    "\n",
    "    logger.success(f\"Finished processing all sensors for location ID: {location_id}\")\n",
    "    return sensors_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Location:\n",
    "    def __init__(self, country: str, name: str, id: int, sensors_data: dict = None):\n",
    "        self.country: str = country\n",
    "        self.name: str = name\n",
    "        self.id: int = id\n",
    "        self.sensors_data: dict = sensors_data\n",
    "\n",
    "    def pull_sensors_data(self):\n",
    "        self.sensors_data = fetch_location_sensors_data(self.id)\n",
    "    \n",
    "    @staticmethod\n",
    "    def save(location: \"Location\"):\n",
    "        if not os.path.isdir(DATA_DIR + f\"/{location.country}_{location.name}\"):\n",
    "            os.mkdir(DATA_DIR + f\"/{location.country}_{location.name}\")\n",
    "\n",
    "        with open(f\"{DATA_DIR}/{location.country}_{location.name}/{location.country}_{location.name}.pkl\", \"wb\") as f:\n",
    "            pkl.dump(location, f)\n",
    "\n",
    "    @staticmethod\n",
    "    def load(location: \"Location\") -> \"Location\":\n",
    "        with open(f\"{DATA_DIR}/{location.country}_{location.name}/{location.country}_{location.name}.pkl\", \"rb\") as f:\n",
    "            location = pkl.load(f)\n",
    "        \n",
    "        return location\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "locations = [\n",
    "    Location(country=\"Costa Rica\", name=\"NASA GSFC Rutgers Calib. N13\", id=3070644),\n",
    "    Location(country=\"Spain\", name=\"Escaldes-Engordany\", id=9742)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-04-20 22:59:26 - __main__ - INFO - \u001b[34mFetching data for location ID: 3070644...\u001b[0m\n",
      "2025-04-20 22:59:26 - __main__ - INFO - \u001b[32mFinished fetch for data of location ID: 3070644\u001b[0m\n",
      "2025-04-20 22:59:26 - __main__ - INFO - \u001b[34mProcessing sensor number 0\u001b[0m\n",
      "2025-04-20 22:59:26 - __main__ - INFO - \u001b[34mProcessing sensor number 0, page 1\u001b[0m\n",
      "2025-04-20 22:59:26 - __main__ - WARNING - \u001b[38;5;214mRemaining requests: 58\u001b[0m\n",
      "2025-04-20 22:59:27 - __main__ - INFO - \u001b[34mProcessing sensor number 0, page 2\u001b[0m\n",
      "2025-04-20 22:59:27 - __main__ - WARNING - \u001b[38;5;214mRemaining requests: 57\u001b[0m\n",
      "2025-04-20 22:59:27 - __main__ - INFO - \u001b[32mFinished processing sensor number 0\u001b[0m\n",
      "2025-04-20 22:59:27 - __main__ - INFO - \u001b[32mFinished processing all sensors for location ID: 3070644\u001b[0m\n",
      "2025-04-20 22:59:27 - __main__ - INFO - \u001b[32mSaved data for location NASA GSFC Rutgers Calib. N13\u001b[0m\n",
      "2025-04-20 22:59:27 - __main__ - INFO - \u001b[34mFetching data for location ID: 9742...\u001b[0m\n",
      "2025-04-20 22:59:27 - __main__ - INFO - \u001b[32mFinished fetch for data of location ID: 9742\u001b[0m\n",
      "2025-04-20 22:59:27 - __main__ - INFO - \u001b[34mProcessing sensor number 0\u001b[0m\n",
      "2025-04-20 22:59:27 - __main__ - INFO - \u001b[34mProcessing sensor number 0, page 1\u001b[0m\n",
      "2025-04-20 22:59:27 - __main__ - WARNING - \u001b[38;5;214mRemaining requests: 55\u001b[0m\n",
      "2025-04-20 22:59:27 - __main__ - INFO - \u001b[34mProcessing sensor number 0, page 2\u001b[0m\n",
      "2025-04-20 22:59:27 - __main__ - WARNING - \u001b[38;5;214mRemaining requests: 54\u001b[0m\n",
      "2025-04-20 22:59:28 - __main__ - INFO - \u001b[34mProcessing sensor number 0, page 3\u001b[0m\n",
      "2025-04-20 22:59:28 - __main__ - WARNING - \u001b[38;5;214mRemaining requests: 53\u001b[0m\n",
      "2025-04-20 22:59:28 - __main__ - INFO - \u001b[34mProcessing sensor number 0, page 4\u001b[0m\n",
      "2025-04-20 22:59:28 - __main__ - WARNING - \u001b[38;5;214mRemaining requests: 52\u001b[0m\n",
      "2025-04-20 22:59:29 - __main__ - INFO - \u001b[34mProcessing sensor number 0, page 5\u001b[0m\n",
      "2025-04-20 22:59:29 - __main__ - WARNING - \u001b[38;5;214mRemaining requests: 51\u001b[0m\n",
      "2025-04-20 22:59:30 - __main__ - INFO - \u001b[34mProcessing sensor number 0, page 6\u001b[0m\n",
      "2025-04-20 22:59:30 - __main__ - WARNING - \u001b[38;5;214mRemaining requests: 50\u001b[0m\n",
      "2025-04-20 22:59:30 - __main__ - INFO - \u001b[34mProcessing sensor number 0, page 7\u001b[0m\n",
      "2025-04-20 22:59:30 - __main__ - WARNING - \u001b[38;5;214mRemaining requests: 49\u001b[0m\n",
      "2025-04-20 22:59:31 - __main__ - INFO - \u001b[34mProcessing sensor number 0, page 8\u001b[0m\n",
      "2025-04-20 22:59:31 - __main__ - WARNING - \u001b[38;5;214mRemaining requests: 48\u001b[0m\n",
      "2025-04-20 22:59:31 - __main__ - INFO - \u001b[34mProcessing sensor number 0, page 9\u001b[0m\n",
      "2025-04-20 22:59:31 - __main__ - WARNING - \u001b[38;5;214mRemaining requests: 47\u001b[0m\n",
      "2025-04-20 22:59:32 - __main__ - INFO - \u001b[34mProcessing sensor number 0, page 10\u001b[0m\n",
      "2025-04-20 22:59:32 - __main__ - WARNING - \u001b[38;5;214mRemaining requests: 46\u001b[0m\n",
      "2025-04-20 22:59:33 - __main__ - INFO - \u001b[34mProcessing sensor number 0, page 11\u001b[0m\n",
      "2025-04-20 22:59:33 - __main__ - WARNING - \u001b[38;5;214mRemaining requests: 45\u001b[0m\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[117]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# For every location, save all info\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m location \u001b[38;5;129;01min\u001b[39;00m locations:\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m     \u001b[43mlocation\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpull_sensors_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      4\u001b[39m     Location.save(location)\n\u001b[32m      6\u001b[39m     \u001b[38;5;28;01mdel\u001b[39;00m location.sensors_data\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[106]\u001b[39m\u001b[32m, line 9\u001b[39m, in \u001b[36mLocation.pull_sensors_data\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m      8\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mpull_sensors_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m----> \u001b[39m\u001b[32m9\u001b[39m     \u001b[38;5;28mself\u001b[39m.sensors_data = \u001b[43mfetch_location_sensors_data\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mid\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[115]\u001b[39m\u001b[32m, line 28\u001b[39m, in \u001b[36mfetch_location_sensors_data\u001b[39m\u001b[34m(location_id)\u001b[39m\n\u001b[32m     24\u001b[39m not_finished = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m     25\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m not_finished:\n\u001b[32m---> \u001b[39m\u001b[32m28\u001b[39m     sensor_response = \u001b[43mfetch_data\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     29\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbase_url\u001b[49m\u001b[43m=\u001b[49m\u001b[43mMEASUREMENTS_ENDPOINT\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     30\u001b[39m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m=\u001b[49m\u001b[43mHEADERS\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     31\u001b[39m \u001b[43m        \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m=\u001b[49m\u001b[43m{\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43msensor_id\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43msensor_id\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     32\u001b[39m \u001b[43m        \u001b[49m\u001b[43mquery_parameters\u001b[49m\u001b[43m=\u001b[49m\u001b[43mquery_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     33\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     35\u001b[39m     sensor_data = sensor_response.json()\n\u001b[32m     37\u001b[39m     logger.info(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mProcessing sensor number \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m, page \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msensor_data[\u001b[33m\"\u001b[39m\u001b[33mmeta\u001b[39m\u001b[33m\"\u001b[39m][\u001b[33m\"\u001b[39m\u001b[33mpage\u001b[39m\u001b[33m\"\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[94]\u001b[39m\u001b[32m, line 26\u001b[39m, in \u001b[36mfetch_data\u001b[39m\u001b[34m(base_url, headers, parameters, query_parameters, verbose)\u001b[39m\n\u001b[32m     23\u001b[39m     base_url = urljoin(base_url, \u001b[33m\"\u001b[39m\u001b[33m?\u001b[39m\u001b[33m\"\u001b[39m + \u001b[33m\"\u001b[39m\u001b[33m&\u001b[39m\u001b[33m\"\u001b[39m.join(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mk\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mv\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m query_parameters.items()))\n\u001b[32m     25\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m headers \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m26\u001b[39m     response = \u001b[43mrequests\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     27\u001b[39m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbase_url\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     28\u001b[39m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m=\u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     29\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     30\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     31\u001b[39m     response = requests.get(\n\u001b[32m     32\u001b[39m         url=base_url,\n\u001b[32m     33\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.12/site-packages/requests/api.py:73\u001b[39m, in \u001b[36mget\u001b[39m\u001b[34m(url, params, **kwargs)\u001b[39m\n\u001b[32m     62\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mget\u001b[39m(url, params=\u001b[38;5;28;01mNone\u001b[39;00m, **kwargs):\n\u001b[32m     63\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33mr\u001b[39m\u001b[33;03m\"\"\"Sends a GET request.\u001b[39;00m\n\u001b[32m     64\u001b[39m \n\u001b[32m     65\u001b[39m \u001b[33;03m    :param url: URL for the new :class:`Request` object.\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     70\u001b[39m \u001b[33;03m    :rtype: requests.Response\u001b[39;00m\n\u001b[32m     71\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m73\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mget\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m=\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.12/site-packages/requests/api.py:59\u001b[39m, in \u001b[36mrequest\u001b[39m\u001b[34m(method, url, **kwargs)\u001b[39m\n\u001b[32m     55\u001b[39m \u001b[38;5;66;03m# By using the 'with' statement we are sure the session is closed, thus we\u001b[39;00m\n\u001b[32m     56\u001b[39m \u001b[38;5;66;03m# avoid leaving sockets open which can trigger a ResourceWarning in some\u001b[39;00m\n\u001b[32m     57\u001b[39m \u001b[38;5;66;03m# cases, and look like a memory leak in others.\u001b[39;00m\n\u001b[32m     58\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m sessions.Session() \u001b[38;5;28;01mas\u001b[39;00m session:\n\u001b[32m---> \u001b[39m\u001b[32m59\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43msession\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m=\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.12/site-packages/requests/sessions.py:589\u001b[39m, in \u001b[36mSession.request\u001b[39m\u001b[34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[39m\n\u001b[32m    584\u001b[39m send_kwargs = {\n\u001b[32m    585\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mtimeout\u001b[39m\u001b[33m\"\u001b[39m: timeout,\n\u001b[32m    586\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mallow_redirects\u001b[39m\u001b[33m\"\u001b[39m: allow_redirects,\n\u001b[32m    587\u001b[39m }\n\u001b[32m    588\u001b[39m send_kwargs.update(settings)\n\u001b[32m--> \u001b[39m\u001b[32m589\u001b[39m resp = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprep\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43msend_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    591\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m resp\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.12/site-packages/requests/sessions.py:703\u001b[39m, in \u001b[36mSession.send\u001b[39m\u001b[34m(self, request, **kwargs)\u001b[39m\n\u001b[32m    700\u001b[39m start = preferred_clock()\n\u001b[32m    702\u001b[39m \u001b[38;5;66;03m# Send the request\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m703\u001b[39m r = \u001b[43madapter\u001b[49m\u001b[43m.\u001b[49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    705\u001b[39m \u001b[38;5;66;03m# Total elapsed time of the request (approximately)\u001b[39;00m\n\u001b[32m    706\u001b[39m elapsed = preferred_clock() - start\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.12/site-packages/requests/adapters.py:667\u001b[39m, in \u001b[36mHTTPAdapter.send\u001b[39m\u001b[34m(self, request, stream, timeout, verify, cert, proxies)\u001b[39m\n\u001b[32m    664\u001b[39m     timeout = TimeoutSauce(connect=timeout, read=timeout)\n\u001b[32m    666\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m667\u001b[39m     resp = \u001b[43mconn\u001b[49m\u001b[43m.\u001b[49m\u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    668\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    669\u001b[39m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[43m=\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    670\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    671\u001b[39m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m.\u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    672\u001b[39m \u001b[43m        \u001b[49m\u001b[43mredirect\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    673\u001b[39m \u001b[43m        \u001b[49m\u001b[43massert_same_host\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    674\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    675\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    676\u001b[39m \u001b[43m        \u001b[49m\u001b[43mretries\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmax_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    677\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    678\u001b[39m \u001b[43m        \u001b[49m\u001b[43mchunked\u001b[49m\u001b[43m=\u001b[49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    679\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    681\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m (ProtocolError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[32m    682\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m(err, request=request)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.12/site-packages/urllib3/connectionpool.py:787\u001b[39m, in \u001b[36mHTTPConnectionPool.urlopen\u001b[39m\u001b[34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[39m\n\u001b[32m    784\u001b[39m response_conn = conn \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m release_conn \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    786\u001b[39m \u001b[38;5;66;03m# Make the request on the HTTPConnection object\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m787\u001b[39m response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_make_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    788\u001b[39m \u001b[43m    \u001b[49m\u001b[43mconn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    789\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    790\u001b[39m \u001b[43m    \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    791\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout_obj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    792\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    793\u001b[39m \u001b[43m    \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m=\u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    794\u001b[39m \u001b[43m    \u001b[49m\u001b[43mchunked\u001b[49m\u001b[43m=\u001b[49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    795\u001b[39m \u001b[43m    \u001b[49m\u001b[43mretries\u001b[49m\u001b[43m=\u001b[49m\u001b[43mretries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    796\u001b[39m \u001b[43m    \u001b[49m\u001b[43mresponse_conn\u001b[49m\u001b[43m=\u001b[49m\u001b[43mresponse_conn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    797\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    798\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    799\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mresponse_kw\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    800\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    802\u001b[39m \u001b[38;5;66;03m# Everything went great!\u001b[39;00m\n\u001b[32m    803\u001b[39m clean_exit = \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.12/site-packages/urllib3/connectionpool.py:534\u001b[39m, in \u001b[36mHTTPConnectionPool._make_request\u001b[39m\u001b[34m(self, conn, method, url, body, headers, retries, timeout, chunked, response_conn, preload_content, decode_content, enforce_content_length)\u001b[39m\n\u001b[32m    532\u001b[39m \u001b[38;5;66;03m# Receive the response from the server\u001b[39;00m\n\u001b[32m    533\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m534\u001b[39m     response = \u001b[43mconn\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgetresponse\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    535\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m (BaseSSLError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    536\u001b[39m     \u001b[38;5;28mself\u001b[39m._raise_timeout(err=e, url=url, timeout_value=read_timeout)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.12/site-packages/urllib3/connection.py:516\u001b[39m, in \u001b[36mHTTPConnection.getresponse\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    513\u001b[39m _shutdown = \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m.sock, \u001b[33m\"\u001b[39m\u001b[33mshutdown\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m    515\u001b[39m \u001b[38;5;66;03m# Get the response from http.client.HTTPConnection\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m516\u001b[39m httplib_response = \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgetresponse\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    518\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    519\u001b[39m     assert_header_parsing(httplib_response.msg)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.python/current/lib/python3.12/http/client.py:1419\u001b[39m, in \u001b[36mHTTPConnection.getresponse\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1417\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m   1418\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1419\u001b[39m         \u001b[43mresponse\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbegin\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1420\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m:\n\u001b[32m   1421\u001b[39m         \u001b[38;5;28mself\u001b[39m.close()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.python/current/lib/python3.12/http/client.py:331\u001b[39m, in \u001b[36mHTTPResponse.begin\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    329\u001b[39m \u001b[38;5;66;03m# read until we get a non-100 response\u001b[39;00m\n\u001b[32m    330\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m331\u001b[39m     version, status, reason = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_read_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    332\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m status != CONTINUE:\n\u001b[32m    333\u001b[39m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.python/current/lib/python3.12/http/client.py:292\u001b[39m, in \u001b[36mHTTPResponse._read_status\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    291\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_read_status\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m--> \u001b[39m\u001b[32m292\u001b[39m     line = \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mreadline\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_MAXLINE\u001b[49m\u001b[43m \u001b[49m\u001b[43m+\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m)\u001b[49m, \u001b[33m\"\u001b[39m\u001b[33miso-8859-1\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    293\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(line) > _MAXLINE:\n\u001b[32m    294\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m LineTooLong(\u001b[33m\"\u001b[39m\u001b[33mstatus line\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.python/current/lib/python3.12/socket.py:707\u001b[39m, in \u001b[36mSocketIO.readinto\u001b[39m\u001b[34m(self, b)\u001b[39m\n\u001b[32m    705\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m    706\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m707\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_sock\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrecv_into\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    708\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m timeout:\n\u001b[32m    709\u001b[39m         \u001b[38;5;28mself\u001b[39m._timeout_occurred = \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.python/current/lib/python3.12/ssl.py:1253\u001b[39m, in \u001b[36mSSLSocket.recv_into\u001b[39m\u001b[34m(self, buffer, nbytes, flags)\u001b[39m\n\u001b[32m   1249\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m flags != \u001b[32m0\u001b[39m:\n\u001b[32m   1250\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m   1251\u001b[39m           \u001b[33m\"\u001b[39m\u001b[33mnon-zero flags not allowed in calls to recv_into() on \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m\"\u001b[39m %\n\u001b[32m   1252\u001b[39m           \u001b[38;5;28mself\u001b[39m.\u001b[34m__class__\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m1253\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnbytes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1254\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1255\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m().recv_into(buffer, nbytes, flags)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.python/current/lib/python3.12/ssl.py:1105\u001b[39m, in \u001b[36mSSLSocket.read\u001b[39m\u001b[34m(self, len, buffer)\u001b[39m\n\u001b[32m   1103\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m   1104\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m buffer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1105\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_sslobj\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1106\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1107\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._sslobj.read(\u001b[38;5;28mlen\u001b[39m)\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# For every location, save all info\n",
    "for location in locations:\n",
    "    location.pull_sensors_data()\n",
    "    Location.save(location)\n",
    "    \n",
    "    del location.sensors_data\n",
    "    \n",
    "    logger.success(f\"Saved data for location {location.name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# 2. Tareas de limpieza y transformación:\n",
    "\n",
    "Se deben realizar las tareas de limpieza y transformación necesarias para poder hacer un comparativo de la evolución de los diferentes indicadores de la calidad del aire en Costa Rica y las otras ciudades.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Eliminar datos no necesarios\n",
    "\n",
    "Primero, dejamos solo datos relevantes para analizar. Es decir, summary, value, parameter y period."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_sensors_data(\n",
    "    sensors_data: dict[int, list[dict]]\n",
    ") -> dict[int, list[dict]]:\n",
    "    \n",
    "    \"\"\"\n",
    "    Clean the sensors data.\n",
    "    :param sensors_data: The sensors data to clean.\n",
    "    :return: The cleaned sensors data.\n",
    "    \"\"\"\n",
    "\n",
    "    cleaned_data = {}\n",
    "    for sensor_id, sensor_data in sensors_data.items():\n",
    "        cleaned_data[sensor_id] = []\n",
    "\n",
    "        for page in sensor_data:\n",
    "            for measurement in page[\"results\"]:\n",
    "                # Data dict\n",
    "                data_dict = {\n",
    "                    \"value\": measurement[\"value\"],\n",
    "                    \"summary\": measurement[\"summary\"],\n",
    "                    \"period\": measurement[\"period\"],\n",
    "                    \"parameter\": measurement[\"parameter\"],\n",
    "                }\n",
    "                cleaned_data[sensor_id].append(data_dict)\n",
    "    \n",
    "    return cleaned_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data\n",
    "locations = [Location.load(location) for location in locations]\n",
    "\n",
    "for location in locations:\n",
    "    location.sensors_data = clean_sensors_data(location.sensors_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Buscamos valores nulos\n",
    "\n",
    "Luego, buscamos valores nulos que puedan interferir en el análisis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-04-20 23:03:53 - __main__ - INFO - \u001b[34mLocation: NASA GSFC Rutgers Calib. N13\u001b[0m\n",
      "2025-04-20 23:03:53 - __main__ - WARNING - \u001b[38;5;214mNull found at: 10669679[0].parameter.displayName\u001b[0m\n",
      "2025-04-20 23:03:53 - __main__ - INFO - \u001b[34m   Parent data: {'id': 2, 'name': 'pm25', 'units': 'µg/m³', 'displayName': None}\u001b[0m\n",
      "2025-04-20 23:03:53 - __main__ - INFO - \u001b[34mLocation: Escaldes-Engordany\u001b[0m\n",
      "2025-04-20 23:03:53 - __main__ - WARNING - \u001b[38;5;214mNull found at: 30389[0].parameter.displayName\u001b[0m\n",
      "2025-04-20 23:03:53 - __main__ - INFO - \u001b[34m   Parent data: {'id': 4, 'name': 'co', 'units': 'µg/m³', 'displayName': None}\u001b[0m\n",
      "2025-04-20 23:03:53 - __main__ - WARNING - \u001b[38;5;214mNull found at: 30389[55].summary.sd\u001b[0m\n",
      "2025-04-20 23:03:53 - __main__ - INFO - \u001b[34m   Parent data: {'min': 200.0, 'q02': 200.0, 'q25': 200.0, 'median': 200.0, 'q75': 200.0, 'q98': 200.0, 'max': 200.0, 'avg': 200.0, 'sd': None}\u001b[0m\n",
      "2025-04-20 23:03:53 - __main__ - WARNING - \u001b[38;5;214mNull found at: 4272958[0].parameter.displayName\u001b[0m\n",
      "2025-04-20 23:03:53 - __main__ - INFO - \u001b[34m   Parent data: {'id': 19843, 'name': 'no', 'units': 'µg/m³', 'displayName': None}\u001b[0m\n",
      "2025-04-20 23:03:53 - __main__ - WARNING - \u001b[38;5;214mNull found at: 30387[0].parameter.displayName\u001b[0m\n",
      "2025-04-20 23:03:53 - __main__ - INFO - \u001b[34m   Parent data: {'id': 5, 'name': 'no2', 'units': 'µg/m³', 'displayName': None}\u001b[0m\n",
      "2025-04-20 23:03:53 - __main__ - WARNING - \u001b[38;5;214mNull found at: 30387[63].summary.sd\u001b[0m\n",
      "2025-04-20 23:03:53 - __main__ - INFO - \u001b[34m   Parent data: {'min': 63.0, 'q02': 63.0, 'q25': 63.0, 'median': 63.0, 'q75': 63.0, 'q98': 63.0, 'max': 63.0, 'avg': 63.0, 'sd': None}\u001b[0m\n",
      "2025-04-20 23:03:53 - __main__ - WARNING - \u001b[38;5;214mNull found at: 30386[0].parameter.displayName\u001b[0m\n",
      "2025-04-20 23:03:53 - __main__ - INFO - \u001b[34m   Parent data: {'id': 3, 'name': 'o3', 'units': 'µg/m³', 'displayName': None}\u001b[0m\n",
      "2025-04-20 23:03:53 - __main__ - WARNING - \u001b[38;5;214mNull found at: 30386[63].summary.sd\u001b[0m\n",
      "2025-04-20 23:03:53 - __main__ - INFO - \u001b[34m   Parent data: {'min': 14.0, 'q02': 14.0, 'q25': 14.0, 'median': 14.0, 'q75': 14.0, 'q98': 14.0, 'max': 14.0, 'avg': 14.0, 'sd': None}\u001b[0m\n",
      "2025-04-20 23:03:53 - __main__ - WARNING - \u001b[38;5;214mNull found at: 30385[0].parameter.displayName\u001b[0m\n",
      "2025-04-20 23:03:53 - __main__ - INFO - \u001b[34m   Parent data: {'id': 1, 'name': 'pm10', 'units': 'µg/m³', 'displayName': None}\u001b[0m\n",
      "2025-04-20 23:03:53 - __main__ - WARNING - \u001b[38;5;214mNull found at: 30385[63].summary.sd\u001b[0m\n",
      "2025-04-20 23:03:53 - __main__ - INFO - \u001b[34m   Parent data: {'min': 17.0, 'q02': 17.0, 'q25': 17.0, 'median': 17.0, 'q75': 17.0, 'q98': 17.0, 'max': 17.0, 'avg': 17.0, 'sd': None}\u001b[0m\n",
      "2025-04-20 23:03:53 - __main__ - WARNING - \u001b[38;5;214mNull found at: 3546106[0].parameter.displayName\u001b[0m\n",
      "2025-04-20 23:03:53 - __main__ - INFO - \u001b[34m   Parent data: {'id': 2, 'name': 'pm25', 'units': 'µg/m³', 'displayName': None}\u001b[0m\n",
      "2025-04-20 23:03:53 - __main__ - WARNING - \u001b[38;5;214mNull found at: 3546106[3].summary.sd\u001b[0m\n",
      "2025-04-20 23:03:53 - __main__ - INFO - \u001b[34m   Parent data: {'min': 11.2, 'q02': 11.2, 'q25': 11.2, 'median': 11.2, 'q75': 11.2, 'q98': 11.2, 'max': 11.2, 'avg': 11.2, 'sd': None}\u001b[0m\n",
      "2025-04-20 23:03:53 - __main__ - WARNING - \u001b[38;5;214mNull found at: 30384[0].parameter.displayName\u001b[0m\n",
      "2025-04-20 23:03:53 - __main__ - INFO - \u001b[34m   Parent data: {'id': 6, 'name': 'so2', 'units': 'µg/m³', 'displayName': None}\u001b[0m\n",
      "2025-04-20 23:03:53 - __main__ - WARNING - \u001b[38;5;214mNull found at: 30384[63].summary.sd\u001b[0m\n",
      "2025-04-20 23:03:53 - __main__ - INFO - \u001b[34m   Parent data: {'min': 0.0, 'q02': 0.0, 'q25': 0.0, 'median': 0.0, 'q75': 0.0, 'q98': 0.0, 'max': 0.0, 'avg': 0.0, 'sd': None}\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def normalize_path(path):\n",
    "    return re.sub(r'\\[\\d+\\]', '[]', path)\n",
    "\n",
    "def find_nulls(obj, path=\"\", parent=None):\n",
    "    nulls = []\n",
    "\n",
    "    if isinstance(obj, dict):\n",
    "        for k, v in obj.items():\n",
    "            full_path = f\"{path}.{k}\" if path else k\n",
    "            nulls.extend(find_nulls(v, full_path, obj))\n",
    "    elif isinstance(obj, list):\n",
    "        for i, item in enumerate(obj):\n",
    "            full_path = f\"{path}[{i}]\"\n",
    "            nulls.extend(find_nulls(item, full_path, item))\n",
    "    elif obj is None:\n",
    "        nulls.append((path, obj, parent))\n",
    "\n",
    "    return nulls\n",
    "\n",
    "seen_paths = set()\n",
    "\n",
    "for location in locations:\n",
    "    logger.info(f\"Location: {location.name}\")\n",
    "    nulls = find_nulls(location.sensors_data)\n",
    "\n",
    "    for path, val, parent in nulls:\n",
    "        generalized = normalize_path(path)\n",
    "        if generalized not in seen_paths:\n",
    "            logger.warning(f\"Null found at: {path}\")\n",
    "            logger.info(f\"   Parent data: {parent}\")\n",
    "            seen_paths.add(generalized)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parece que los valores nulos son los nombres de los parámetros (que no son muy importantes), y las desviaciones estándar de algunos valores agregados (pero solo aquellos donde solo existe un valor, lo cual tiene sentido). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# 3. Implementación en Google Colab:\n",
    "\n",
    "Realizar la implementación en Google Colab. Si existen problemas de desempeño, se puede optar por otro entorno, lo cual debe ser anotado en la documentación del notebook así como en la presentación.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# 4. Análisis y comparación:\n",
    "\n",
    "Se debe realizar un análisis EDA que incluya análisis univariable y multivariable.\n",
    "\n",
    "Analizar las tendencias de los indicadores para las diferentes ciudades y hacer comparaciones entre diferentes países y ciudades.\n",
    "\n",
    "Incluir posibles correlaciones entre las variables y parámetros de calidad del aire de cada país/ciudad.\n",
    "\n",
    "Utilizar diferentes tipos de visualizaciones relevantes para el análisis.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# 5. Conclusiones y Recomendaciones:\n",
    "\n",
    "Extraer conclusiones sobre la evolución de la calidad del aire en Costa Rica y las ciudades seleccionadas, explicando cómo los datos sustentan estas conclusiones.\n",
    "\n",
    "Buscar información sobre las políticas ambientales y regulaciones en estas ciudades y mostrar cómo los datos reflejan el efecto de estas políticas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KSQI1hom40h-"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyNxGvRAG9aLOhVckcngOJm0",
   "include_colab_link": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
